import pandas as pd
import numpy as np
from concurrent.futures import ProcessPoolExecutor
import os

# File paths
file_a = 'path/to/file_a.xlsx'
file_b = 'path/to/file_b.xlsx'
file_c = 'path/to/file_c.xlsx'
output_file = 'path/to/output_file.xlsx'

def read_excel(file_path, usecols):
    return pd.read_excel(file_path, usecols=usecols)

def process_chunk(chunk_data, df_b, df_c):
    chunk = pd.DataFrame(chunk_data, columns=['Account Id - A', 'Account - A Name', 'Account Id - B', 'Account - B Name'])
    
    # Merge chunk with B and C
    merged = pd.merge(chunk, df_b, on='Account Id - A', how='left')
    merged = pd.merge(merged, df_c, on='Account Id - B', how='left')
    
    # Aggregate emails
    merged['Account - A Email'] = merged.groupby('Account Id - A')['Account - A Email'].transform(lambda x: ', '.join(x.dropna().unique()))
    merged['Account - B Email'] = merged.groupby('Account Id - B')['Account - B Email'].transform(lambda x: ', '.join(x.dropna().unique()))
    
    # Select required columns
    return merged[['Account Id - A', 'Account Id - B', 'Account - A Email', 'Account - B Email']].drop_duplicates()

if __name__ == '__main__':
    # Read files A, B, and C
    df_a = read_excel(file_a, usecols=['Account Id - A', 'Account - A Name', 'Account Id - B', 'Account - B Name'])
    df_b = read_excel(file_b, usecols=['Account Id - A', 'Account - A Email'])
    df_c = read_excel(file_c, usecols=['Account Id - B', 'Account - B Email'])

    # Aggregate emails in df_b and df_c
    df_b = df_b.groupby('Account Id - A')['Account - A Email'].agg(lambda x: ', '.join(x.dropna().unique())).reset_index()
    df_c = df_c.groupby('Account Id - B')['Account - B Email'].agg(lambda x: ', '.join(x.dropna().unique())).reset_index()

    # Process file A in chunks
    chunk_size = 50000  # Adjust based on available memory
    num_chunks = int(np.ceil(len(df_a) / chunk_size))
    
    output_chunks = []

    with ProcessPoolExecutor(max_workers=os.cpu_count()) as executor:
        futures = []
        for i in range(num_chunks):
            start = i * chunk_size
            end = min((i + 1) * chunk_size, len(df_a))
            chunk_data = df_a.iloc[start:end].values.tolist()
            futures.append(executor.submit(process_chunk, chunk_data, df_b, df_c))
        
        for future in futures:
            output_chunks.append(future.result())

    # Combine all processed chunks
    final_output = pd.concat(output_chunks, ignore_index=True)

    # Write to Excel
    final_output.to_excel(output_file, index=False)

print(f"Output written to {output_file}")
